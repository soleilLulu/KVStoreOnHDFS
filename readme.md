需要了解的接口包括

hadoop中的
SequenceFile，
Writable，
Progressable，
ByteArrayOutputStream
org.apache.hadoop.record.Utils.readVInt

java中的
ConcurrentSkipListMap，
ObjectOutputStream

需要深度了解的知识：
HDFS文件存储的方式
如何知道HDFS一条记录的长度并且从中读取


系统索引的设计：
从目前看来，我们设计的是将一段key到value之间的值存到一个文件后，通过一个含有startKey和endKey以及存储文件的路径的kv值记录该文件的内容

如何中断恢复：
在测试中有一个情况是将kvpod杀死后重启，是否数据会丢失。这就涉及了将数据先写入日志然后从日志中读取的过程。写入日志的过程是持续的。
一旦一段数据满了，就可以将内存中的记录填入底层文件系统并且将对应的日志文件删除。
如果在重启的时候发现有日志文件没有删除，那么就会读入到当系统的内存等待下一次满了以后一次性输出